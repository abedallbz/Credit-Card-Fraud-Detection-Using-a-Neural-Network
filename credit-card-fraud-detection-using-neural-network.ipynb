{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ideas for Fraud check : \n",
    "# 1) Check locations of transaction - 2 different transactions in a short period. \n",
    "# 2) User's Credit card use history \n",
    "# 3) Classifcation on different frauds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "479748ca-639b-4448-ae21-3681170a65de",
    "_uuid": "22d41ba02b32da646889dba983ba08c08cb38f08",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creditcard.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "0841452d-e539-4ece-85d1-15d360043c09",
    "_uuid": "86182358544562cbe369b51e9814655acde61586",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data set \n",
    "df = pd.read_csv(\"../input/creditcard.csv\")\n",
    "\n",
    "# Exploring the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ea253bf4-b913-4aaf-8926-eee7235728b6",
    "_uuid": "b868348d19df2cf2a0899f116a9fdaeec9e609e3",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "1b5465a9-415a-4234-bda7-83f476de6d12",
    "_uuid": "7283579147c0d1ee73527b045b03b9544ff3770b",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is any null values\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "981699a4-657a-4d67-8ec4-31591d07b0b3",
    "_uuid": "dcc6f593cc27cadcfcccb1ab25e3e52f200b4747",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No missing values in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "029fac77-6ded-4a18-a970-e548a49692b4",
    "_kg_hide-input": false,
    "_uuid": "5906208cac3075b9b5d6889561210b3e990cd2ad",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Creating Train Set, Dev Set & Train set\n",
    "\n",
    "# Converting the csv data into matrix \n",
    "columns = \"Time V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 V21 V22 V23 V24 V25 V26 V27 V28 Amount\".split()\n",
    "X = pd.DataFrame.as_matrix(df,columns=columns)\n",
    "Y = df.Class\n",
    "Y = Y.reshape(Y.shape[0],1)\n",
    "X.shape\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.06)\n",
    "X_test, X_dev, Y_test, Y_dev = train_test_split(X_test,Y_test, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "23d6f550-aba4-4046-88c8-c8efca8194ac",
    "_uuid": "3290a1a038c9e414589b9390389aa1fbb6929a39",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  24,  509,  618,  964, 2289, 2729, 3266, 3852, 4591, 5601, 7624,\n",
       "        8101, 8157, 8452]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is Classification Values - 0/1 in training set and other set \n",
    "\n",
    "np.where(Y_train == 1)\n",
    "np.where(Y_test == 1)\n",
    "np.where(Y_dev == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b8b37d86-23c3-4185-afb4-fc9e796f3410",
    "_uuid": "e8f7ddedd7937d9b340fd79e92a311667acf42e7",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training Examples : 267718\n",
      "No of test Examples : 8544\n",
      "No of dev Examples : 8545\n",
      "Shape of training data : (267718, 30)\n",
      "Shape of test data : (8544, 30)\n",
      "Shape of dev data : (8545, 30)\n",
      "Shape of Y test data : (8544, 1)\n",
      "Shape of Y dev data : (8545, 1)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape's of the new data set as matrix \n",
    "print(\"No of training Examples : \"+str(X_train.shape[0]))  # 94% data \n",
    "print(\"No of test Examples : \"+str(X_test.shape[0]))       # 3% data\n",
    "print(\"No of dev Examples : \"+str(X_dev.shape[0]))         # 3% data\n",
    "print(\"Shape of training data : \"+str(X_train.shape))\n",
    "print(\"Shape of test data : \"+str(X_test.shape))\n",
    "print(\"Shape of dev data : \"+str(X_dev.shape))\n",
    "print(\"Shape of Y test data : \"+str(Y_test.shape))\n",
    "print(\"Shape of Y dev data : \"+str(Y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "99f15a8c-4d5f-4b5e-9af0-56ee0bdf2e87",
    "_uuid": "19e721fe5df41744cbf1669a5f6ca0dd817d7635",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training Examples : (30, 267718)\n",
      "No of test Examples : (1, 267718)\n",
      "No of X_dev Examples : (30, 8545)\n",
      "No of Y_dev test Examples : (1, 8545)\n",
      "No of X_test Examples : (30, 8544)\n",
      "No of Y_test Examples : (1, 8544)\n",
      "No of Sanity_test : [ 1.54379000e+05  1.84243674e+00  2.83438048e-01 -6.77139216e-01\n",
      "  3.74157531e+00]\n"
     ]
    }
   ],
   "source": [
    "#Flatten the data to so that all Features/X Variables \n",
    "X_train_flatten = X_train.reshape(X_train.shape[0],-1).T\n",
    "Y_train_flatten = Y_train.reshape(Y_train.shape[0],-1).T\n",
    "X_dev_flatten = X_dev.reshape(X_dev.shape[0],-1).T\n",
    "Y_dev_flatten = Y_dev.reshape(Y_dev.shape[0],-1).T\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0],-1).T\n",
    "Y_test_flatten = Y_test.reshape(Y_test.shape[0],-1).T\n",
    "\n",
    "print(\"No of training Examples : \"+str(X_train_flatten.shape))  \n",
    "print(\"No of test Examples : \"+str(Y_train_flatten.shape))  \n",
    "print(\"No of X_dev Examples : \"+str(X_dev_flatten.shape))  \n",
    "print(\"No of Y_dev test Examples : \"+str(Y_dev_flatten.shape))  \n",
    "print(\"No of X_test Examples : \"+str(X_test_flatten.shape))  \n",
    "print(\"No of Y_test Examples : \"+str(Y_test_flatten.shape))\n",
    "print(\"No of Sanity_test : \"+str(X_train_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "6a35d7a9-d1d7-4f24-b9a7-3e999579ec9c",
    "_uuid": "262fd43b1a97c87f2529dfcda8a6761089d92d18",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of X_train_set shape : (30, 267718)\n",
      "No of Y_train_set shape : (1, 267718)\n"
     ]
    }
   ],
   "source": [
    "# Normalize features and create final Train set \n",
    "X_train_set = preprocessing.normalize(X_train_flatten)\n",
    "Y_train_set = Y_train_flatten\n",
    "\n",
    "print(\"No of X_train_set shape : \"+str(X_train_set.shape))  \n",
    "print(\"No of Y_train_set shape : \"+str(Y_train_set.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "5f27ff04-874e-4d2f-8ca5-e7878fcd5e24",
    "_uuid": "f1aaea3cbf9087ee414188e394965e2eb2eb3a5d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcation to intialize weights for forward propogration \n",
    "def intialize_parameters(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    for l in range(1,L):\n",
    "        parameters['W'+str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b'+str(l)] = np.zeros((layer_dims[l],1))\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "cd692215-b46d-4da3-bd78-1e939fd4098f",
    "_uuid": "f4088a9a7bcab56a54147cdcce79716e67dafdde",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 =[[ 5.82746677e-03 -6.72815223e-03  2.71865351e-03 -7.84429385e-03\n",
      "  -9.12317865e-04  1.18803987e-02  6.47977349e-03 -5.73435574e-04\n",
      "   1.41947203e-02 -3.51833272e-03 -7.15683862e-03  1.38850554e-02\n",
      "   1.63785433e-02 -6.82729727e-03  2.93159900e-03 -3.48869137e-03\n",
      "   6.30933985e-03 -1.01223221e-02  5.66738535e-03 -7.80590225e-03\n",
      "  -1.43414457e-02 -9.81037240e-03 -1.76363351e-03  7.85391488e-03\n",
      "  -1.27744952e-02  1.53227892e-02  1.92357424e-03 -1.08104913e-02\n",
      "  -1.16257579e-03 -7.61112735e-03]\n",
      " [ 5.42164872e-03  2.49167332e-03 -3.10549039e-03 -4.53899084e-03\n",
      "  -3.18098385e-03 -5.10755476e-03 -4.83802693e-03 -1.05063555e-02\n",
      "  -2.92711152e-03 -5.20777009e-03  3.45108527e-03  2.02873357e-03\n",
      "  -8.53742275e-03  4.13848169e-03  9.00178025e-03 -9.52728225e-03\n",
      "  -1.03989331e-02  1.21488691e-03 -7.89317596e-03  1.18804793e-02\n",
      "   4.00370627e-04  8.24657099e-04  2.43445251e-03 -5.71063153e-03\n",
      "  -3.95560836e-03 -7.59215936e-03  5.93918252e-03  7.83932590e-03\n",
      "  -6.36164540e-04  1.04014732e-02]\n",
      " [-5.34992535e-05 -2.43472877e-03 -1.30013672e-02  2.17664117e-02\n",
      "   1.66091272e-02 -5.34696795e-03 -7.38725466e-03  8.18228025e-03\n",
      "  -6.16129814e-04 -1.18113600e-02 -7.37889749e-03 -9.39674256e-03\n",
      "   9.66893891e-03 -9.93619272e-03  6.37536682e-03  5.16666229e-03\n",
      "  -1.45596910e-02  1.39832733e-04  3.76850057e-03  6.90300287e-03\n",
      "  -3.69699166e-04 -8.30538548e-03 -1.04473409e-02 -2.71575455e-03\n",
      "  -3.51878201e-03  1.94053791e-03  2.06443680e-03  1.46365574e-02\n",
      "  -1.57192637e-02  1.86968409e-02]\n",
      " [ 1.14166043e-02 -5.09014426e-03  1.26278339e-02 -1.64305393e-02\n",
      "  -7.05965089e-03  1.36013070e-02  1.41122933e-02  8.44105973e-03\n",
      "  -9.86104418e-03 -7.30439748e-03  8.31893742e-03 -8.94952715e-03\n",
      "   9.81445333e-03 -2.10014620e-02 -7.13762981e-03 -1.07962495e-02\n",
      "  -1.08261694e-02  8.60896169e-03  1.66891900e-03 -3.00170500e-03\n",
      "  -7.23014690e-03  1.96972914e-02  6.53913887e-03  5.23350586e-03\n",
      "   3.91693290e-04 -9.21126635e-03 -2.02822552e-03  1.42283622e-02\n",
      "   1.11358864e-02  3.45358121e-03]\n",
      " [ 1.34076509e-02  4.73508194e-04 -1.26136612e-02 -1.15609318e-02\n",
      "   1.61138885e-02  1.37846914e-03  1.33455749e-02 -2.35747407e-02\n",
      "  -5.26573212e-03  1.31402392e-02  7.44169131e-04  3.76091870e-03\n",
      "  -5.05568833e-03  2.29602402e-04 -3.61280770e-03  5.86143197e-03\n",
      "  -1.38457913e-02  4.49934146e-03  9.36782063e-03 -9.71593656e-03\n",
      "  -2.10291264e-03  1.76744578e-03  2.47740831e-02  3.98533286e-03\n",
      "  -1.67292140e-03  5.96320957e-03  2.81046645e-03 -4.46578738e-03\n",
      "  -1.50600778e-02 -8.73659582e-03]\n",
      " [ 7.03069733e-03  9.50992714e-04  5.50334508e-03 -1.42816060e-02\n",
      "   7.94034566e-03  1.11720211e-02 -9.97274509e-03  3.07036134e-03\n",
      "  -1.77980411e-02  5.51740750e-03  2.75073191e-02  7.79920121e-03\n",
      "  -1.43485018e-02 -1.73261984e-03 -2.33475105e-02  2.36334709e-03\n",
      "  -1.47068818e-03 -6.97086544e-03 -7.02316600e-03 -1.62933348e-02\n",
      "   4.26293383e-03 -1.18990096e-02 -7.10327759e-03  5.17258366e-03\n",
      "  -5.07422889e-03  3.50172881e-03 -1.41740573e-03 -2.18653157e-03\n",
      "   7.95583013e-03 -1.06011830e-03]\n",
      " [ 8.93908266e-03  5.82161962e-03  5.89916181e-03 -2.37190524e-02\n",
      "   4.74948145e-03  9.28509367e-03  1.64939910e-02  4.30310027e-03\n",
      "  -3.33008788e-03  9.29288708e-03 -2.61822920e-03  7.04062861e-03\n",
      "   1.36686534e-02  7.50679228e-03 -5.19984117e-03  1.28765490e-02\n",
      "  -3.89367753e-03 -5.00965581e-03 -3.01462941e-02  1.62898682e-03\n",
      "  -1.27866632e-02  3.19672713e-03 -1.19251620e-02  2.29016927e-03\n",
      "   4.13560875e-03 -1.01317511e-02 -1.15105352e-03  1.68667519e-03\n",
      "  -5.59561306e-03 -5.56699767e-03]\n",
      " [-1.02035986e-02 -1.47545455e-03  1.81849663e-02  1.01991353e-03\n",
      "  -7.11133607e-04  4.76590348e-03  2.00129842e-03 -6.90720412e-04\n",
      "   4.45875239e-03 -7.29723852e-03 -4.79037511e-03 -4.57353400e-03\n",
      "  -3.98905003e-03 -2.95173307e-03 -1.07071134e-02  5.47478140e-03\n",
      "   1.25601186e-02  2.42818348e-03  6.35253266e-03 -6.72507268e-03\n",
      "  -1.46021399e-03  1.90959362e-03  6.25330347e-03  3.17569364e-03\n",
      "   1.37313751e-02  3.29237544e-03 -7.07370870e-03  5.43850726e-03\n",
      "  -5.07124267e-03  3.57407618e-03]\n",
      " [ 2.53475807e-03 -5.84020188e-03  1.82859236e-03 -2.24574569e-03\n",
      "   1.26749812e-02  9.80321328e-04 -9.26389271e-03  7.07499948e-04\n",
      "   1.48822466e-02  1.34020371e-02  1.30760500e-02 -1.10467905e-02\n",
      "   3.98745023e-03  5.71128898e-03 -1.93994333e-03 -4.97392360e-03\n",
      "  -1.13834641e-02 -3.53724389e-04 -8.13775064e-03  2.74409989e-03\n",
      "   1.26304233e-03  3.24478213e-03  1.35987378e-02 -2.60423955e-03\n",
      "   8.91362493e-03 -2.35509607e-02 -2.37297635e-02 -2.39244907e-03\n",
      "  -4.91522995e-03  9.37222931e-04]\n",
      " [ 5.40152618e-03 -8.72272389e-03  2.10341067e-02  3.06515778e-03\n",
      "  -1.14720975e-04  2.77816200e-03 -1.00252795e-02 -5.45770341e-03\n",
      "  -8.45102731e-03  6.55781662e-04  6.35133705e-03  8.56990453e-03\n",
      "   8.81400805e-03  1.62260033e-02  7.04102563e-03 -6.22485775e-03\n",
      "  -2.92171124e-03  6.58265176e-03 -3.98087966e-03  1.35156452e-02\n",
      "   4.71001331e-03 -6.47946657e-03 -1.27497935e-02  8.55888367e-03\n",
      "   9.80480921e-03  7.47622665e-03 -3.59525886e-04  1.63291368e-02\n",
      "   1.44984585e-02  5.72350715e-04]\n",
      " [ 1.05512039e-03  1.60499592e-02  2.90303614e-03  8.91090819e-04\n",
      "  -8.38249070e-03  1.37859078e-02 -9.16687874e-03 -5.99062756e-03\n",
      "  -1.76343926e-03  4.18368964e-03 -1.23830118e-02  6.62457219e-03\n",
      "   9.73845895e-04 -1.13843239e-02  1.26703255e-02  2.59958337e-03\n",
      "  -2.01511516e-02  1.03760610e-03 -1.39500407e-02 -1.33587094e-02\n",
      "  -5.21250629e-03  1.31067146e-03 -1.57939583e-02 -8.78554362e-03\n",
      "  -2.92553840e-02 -6.48667406e-03  2.86964037e-03 -1.42085552e-02\n",
      "  -7.51615101e-03  2.47468793e-03]\n",
      " [-5.63428756e-03 -1.43245218e-03 -8.86536386e-03  2.43748878e-03\n",
      "  -2.83710643e-03 -8.02443217e-03  3.58322904e-03  1.61346630e-02\n",
      "  -5.14246243e-03  1.42400387e-03  7.45598820e-03 -1.50407183e-02\n",
      "  -4.21276359e-03  1.50640300e-02 -1.11209098e-02  5.77271984e-03\n",
      "  -4.99634983e-03 -5.85402745e-03  8.22353994e-04 -1.02387782e-02\n",
      "  -1.49840055e-02  1.34393685e-03  1.23891500e-03 -1.02420749e-02\n",
      "   1.59714116e-02 -1.10091388e-02 -2.00617160e-02  1.89059451e-03\n",
      "   7.17842910e-03 -1.29852154e-03]\n",
      " [-6.36871748e-03 -1.77510394e-03  1.47641683e-03  7.42988449e-03\n",
      "  -3.22451902e-03  2.12346203e-02 -4.54308867e-03 -1.71960678e-02\n",
      "   1.22114664e-02  1.61399967e-02 -7.35735205e-04 -9.94889042e-03\n",
      "  -3.30422107e-03  1.03916193e-02  3.93347408e-03 -1.82776797e-02\n",
      "  -2.06572428e-02 -1.46173309e-03 -8.21633386e-04 -3.23473902e-03\n",
      "  -1.30719012e-02  1.21533930e-02 -4.58582973e-03 -1.67424094e-03\n",
      "   1.19395998e-02 -5.89089343e-03  1.41724030e-02  1.06274655e-03\n",
      "  -2.05521326e-02  1.13568390e-02]\n",
      " [-3.78701322e-03 -1.05614844e-02 -1.08468465e-03  1.11969654e-02\n",
      "   7.39566665e-03 -3.78164157e-04 -4.35953906e-03  3.09616603e-03\n",
      "   9.41018998e-03 -1.24632083e-02  1.89038277e-03 -5.80145745e-03\n",
      "   4.41009203e-03 -9.52198403e-03 -4.37960082e-03  9.96311504e-03\n",
      "   1.79183360e-02 -7.88055412e-03 -1.39392133e-02  4.17919244e-03\n",
      "   9.55909612e-03  1.35672323e-02 -1.15432463e-02  6.53324305e-03\n",
      "   5.08855249e-03 -5.52584919e-03 -6.78256608e-03  1.05520045e-03\n",
      "  -6.98332656e-03  3.52952608e-03]\n",
      " [ 2.02052489e-02  6.41047979e-03  2.40662895e-03  1.23893527e-02\n",
      "   4.82216840e-04  1.11953083e-02 -2.24078858e-03 -1.87154649e-02\n",
      "  -1.13205504e-02  1.54346246e-02  7.89418366e-03  1.11547755e-04\n",
      "   1.81049177e-03  4.79160777e-03 -9.54357887e-03  1.53535158e-02\n",
      "  -1.06818318e-02  9.48956893e-03 -1.19743031e-02  4.65717334e-05\n",
      "  -1.62437724e-03 -1.12417840e-02 -4.89925373e-03  1.39917267e-02\n",
      "   1.58465868e-02 -2.56869587e-03 -2.74311640e-03 -8.83332845e-03\n",
      "   5.60910788e-03 -1.87909906e-03]\n",
      " [-3.55843169e-04 -1.12557455e-02 -8.85011242e-04 -1.32221836e-02\n",
      "   4.53400994e-03 -1.19276998e-02  7.61957725e-03 -4.51510689e-03\n",
      "   1.32331607e-02  1.13820921e-02 -1.44748805e-02  1.07031053e-03\n",
      "  -1.06034349e-02  2.13757615e-03  9.47391781e-03  8.78346128e-03\n",
      "   1.14358530e-02  6.62374848e-03 -1.51545808e-02 -6.88792798e-03\n",
      "   9.52796656e-03  6.98830053e-03 -1.08445262e-02  5.39197053e-03\n",
      "  -4.85281529e-03  1.73309447e-02 -7.47223921e-03  3.08859677e-03\n",
      "   1.62161020e-02 -1.76951741e-03]\n",
      " [-4.78128410e-03 -1.39623330e-02  4.25185620e-03  6.29087033e-03\n",
      "  -4.27471535e-03 -1.92712568e-02 -2.54874210e-03  6.69424755e-03\n",
      "  -1.19984037e-02 -3.32541423e-03 -1.36134248e-02 -2.44296952e-03\n",
      "   5.70672792e-03  1.16693743e-02 -1.13102441e-02 -1.69369015e-03\n",
      "   3.96659647e-03  8.54763322e-03 -1.83391622e-02 -1.24342934e-03\n",
      "   2.92561599e-03 -1.25187060e-02 -1.60504508e-02  6.02649951e-03\n",
      "   8.50261128e-04 -1.47722566e-02 -1.20475412e-02  2.09058773e-02\n",
      "  -5.55531862e-03 -2.62989178e-04]\n",
      " [ 6.79961100e-03 -3.13596436e-03 -9.03589828e-03  1.03375512e-02\n",
      "   1.51369789e-03 -1.63720917e-02  1.17903691e-02 -1.43476586e-02\n",
      "  -1.21121712e-02 -4.38648410e-03 -1.15866060e-02 -1.04427687e-03\n",
      "   9.88006146e-03 -1.23959541e-02  1.72485460e-03 -9.49177457e-03\n",
      "   1.88999430e-03  1.72272268e-03  7.80045122e-04  4.52774104e-03\n",
      "   7.41555569e-03 -2.44009736e-03 -1.13598655e-03 -5.04282342e-03\n",
      "   1.03615340e-02  1.10866990e-02  8.55255673e-03 -1.52920777e-02\n",
      "   2.65249953e-03 -5.34354075e-04]\n",
      " [-1.80883975e-03  1.21120053e-02  1.83281099e-03  1.55071876e-02\n",
      "   1.17058345e-02  1.75011665e-03 -7.84141846e-03 -3.26272500e-03\n",
      "   3.66213005e-02 -7.88786316e-03  9.41363194e-03 -7.71478023e-04\n",
      "  -2.07452043e-03 -1.24880904e-02  3.85338471e-03  1.16981286e-02\n",
      "   2.53976268e-03  1.14551458e-02  8.44126648e-03 -1.12729512e-02\n",
      "  -8.34696422e-06  1.02183884e-02  7.75139263e-03 -5.26311995e-03\n",
      "  -6.62293698e-03  2.60404564e-03 -2.10395241e-02  2.01432254e-03\n",
      "   1.12208675e-02 -1.58007526e-02]\n",
      " [-1.35483218e-02 -8.66333689e-03  4.26223225e-03 -9.62324329e-03\n",
      "   2.61432811e-04 -2.47918206e-03  3.72457719e-03  5.30402161e-03\n",
      "  -1.96274434e-03  1.75137100e-03  1.08408703e-02 -1.08393108e-02\n",
      "  -1.21954249e-02  9.54955445e-03  3.62609863e-03 -2.80256624e-03\n",
      "   9.27000457e-03 -1.30485083e-02  2.05165032e-02  5.67143822e-03\n",
      "   1.33601232e-02  2.14133055e-02 -1.20974719e-02  7.72711894e-03\n",
      "   7.20461278e-03  2.14457015e-03  1.42803959e-02  3.66867354e-03\n",
      "  -2.01696739e-03  1.63054995e-02]]\n",
      "b1 =[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 =[[-0.00388175  0.00151851 -0.01299009  0.00142181 -0.00647297 -0.00077955\n",
      "  -0.01050855 -0.0040092   0.01474557  0.00911896 -0.00310777 -0.0029634\n",
      "   0.00963578 -0.02162088  0.0159973  -0.00259202 -0.01358704  0.00774422\n",
      "  -0.00978993  0.00266981]\n",
      " [-0.00594197 -0.0156623  -0.00432025  0.00740909 -0.01064404  0.00992688\n",
      "   0.01024813  0.0032564  -0.01542256 -0.00127965 -0.02174706  0.00792017\n",
      "  -0.00240804  0.01223496  0.01421774 -0.01470985 -0.00615656  0.00077863\n",
      "   0.00876881  0.00842214]\n",
      " [ 0.01136187 -0.00361822  0.00707391 -0.01016235  0.01039723  0.00039342\n",
      "  -0.03167386 -0.00763992  0.01734843 -0.0069454   0.01866515  0.01374995\n",
      "   0.00145682  0.00474576  0.00711775 -0.00156048  0.0144493   0.00225739\n",
      "   0.01378017 -0.01372615]\n",
      " [ 0.01256609 -0.01183719 -0.00094914  0.0062437   0.00110141  0.01425831\n",
      "  -0.01409667  0.01315949  0.00351421 -0.00056668 -0.01328801 -0.00041289\n",
      "  -0.01246569 -0.00390389 -0.00156959 -0.02713831 -0.02085814 -0.01164503\n",
      "   0.01648893 -0.00753227]\n",
      " [ 0.00914909 -0.0085506   0.00257447  0.00806138 -0.02156391 -0.00851103\n",
      "  -0.00299844  0.00238977  0.01654344 -0.01535224 -0.00742385 -0.00321801\n",
      "   0.00852547 -0.0001995  -0.0133702  -0.00171902 -0.00083154 -0.01366711\n",
      "   0.006069   -0.00214646]\n",
      " [ 0.00671481 -0.01310933  0.007639   -0.00039179 -0.00639622  0.00648453\n",
      "   0.00298031  0.03079759 -0.01323439  0.01266312  0.00613361  0.00528647\n",
      "   0.01678817  0.00315153 -0.00164184  0.01011238 -0.00281229  0.00033465\n",
      "  -0.00722761 -0.01251996]\n",
      " [ 0.00901005  0.00608015 -0.00289153  0.002049   -0.00502034  0.00630347\n",
      "  -0.01806963  0.00337266  0.0066738   0.01623585  0.0089402  -0.01141044\n",
      "  -0.01308849 -0.00331054  0.00393043  0.00384484  0.01265648  0.01660693\n",
      "   0.0077493   0.00205182]\n",
      " [-0.01274454  0.00576307 -0.01184881  0.00973802  0.01476687  0.00971753\n",
      "  -0.0027309   0.00424798 -0.00103583 -0.00090185  0.00200199 -0.00712356\n",
      "  -0.01420058 -0.0109606   0.01523838  0.0091492   0.00114336  0.0030122\n",
      "  -0.00505146  0.00452144]\n",
      " [ 0.01641424  0.00148224 -0.00100595 -0.01488852  0.00082026 -0.01824965\n",
      "  -0.00811251 -0.00819947  0.00963346  0.00544652  0.00306808  0.00236951\n",
      "  -0.00691307  0.02094244 -0.00250169  0.01969862  0.0036348  -0.00664537\n",
      "   0.00533764 -0.01160091]\n",
      " [ 0.00687774  0.00614976 -0.00463581 -0.0140892   0.01748715  0.01450463\n",
      "  -0.00412438  0.00580286  0.00292962 -0.00218204 -0.00580115  0.01193005\n",
      "  -0.00412341  0.00935712 -0.0017614  -0.0075778  -0.00087356 -0.00450354\n",
      "  -0.00747439 -0.00763582]]\n",
      "b2 =[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W3 =[[-0.00252447 -0.00092329  0.01736048 -0.00221733  0.02086768  0.00858874\n",
      "  -0.00686131 -0.01720293  0.00386663  0.00615582]\n",
      " [-0.00819547 -0.0206715   0.01787476 -0.00540691  0.00103896 -0.00071926\n",
      "   0.00863393  0.01052675 -0.01398562  0.00318104]\n",
      " [-0.01883751  0.00492439 -0.005575   -0.00143438 -0.01526186 -0.00243984\n",
      "   0.00605559  0.01179094  0.01810863 -0.01090433]\n",
      " [-0.00159256 -0.0005933   0.01199662 -0.00418792  0.0008004  -0.00504388\n",
      "   0.00183374 -0.00413467 -0.00330421 -0.01396934]\n",
      " [ 0.00419376  0.01917481 -0.00676844  0.01535404  0.000462    0.00511161\n",
      "   0.01726904 -0.00477866 -0.00134505 -0.00531179]]\n",
      "b3 =[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W4 =[[-0.00786833 -0.01108062  0.00135929 -0.01825666 -0.00889369]\n",
      " [-0.03086463 -0.01725017  0.01436135  0.00924728 -0.00093174]]\n",
      "b4 =[[0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# Testing if the function works \n",
    "parameters = intialize_parameters([30,20,10,5,2])\n",
    "print(\"W1 =\" + str(parameters[\"W1\"]))\n",
    "print(\"b1 =\" + str(parameters[\"b1\"]))\n",
    "print(\"W2 =\" + str(parameters[\"W2\"]))\n",
    "print(\"b2 =\" + str(parameters[\"b2\"]))\n",
    "print(\"W3 =\" + str(parameters[\"W3\"]))\n",
    "print(\"b3 =\" + str(parameters[\"b3\"]))\n",
    "print(\"W4 =\" + str(parameters[\"W4\"]))\n",
    "print(\"b4 =\" + str(parameters[\"b4\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "1fc51a3c-f907-4f27-80f4-96624ca06d7d",
    "_uuid": "e6d2308bdea3abd099abb65d87569c2dddb14640",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the sigmoid function \n",
    "def sigmoid(z):\n",
    "    \n",
    "    s = 1/(1+np.exp(-z))\n",
    "    cache = z\n",
    "    return s,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "bc6e7bf7-fe86-4903-ba78-2067017f6410",
    "_uuid": "50917cea8c57ce5750326d0ade7a9ebf74362aab",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.88079708, 0.99908895]), array([2, 7]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test sigmoid function \n",
    "sigmoid(np.array(([2,7]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "179c9477-4d5f-49aa-b0f3-b35932ffb34e",
    "_uuid": "3e5672dc2c0cc71b3c9995b5c6e5cf257059922b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the relu function\n",
    "def relu(z):\n",
    "    \n",
    "    r = np.maximum(0,z)\n",
    "    cache = z\n",
    "    return r,cache\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "480a40d0-2865-4822-8abf-5f512dcaba63",
    "_uuid": "e6ec43668956470dbe88deb1a529d054130ef6d2",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  0, 21]), [1, -1, 21])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing relu function \n",
    "relu([1,-1,21]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "3e95543c-87ad-40fe-a32f-0932eec4cddf",
    "_uuid": "9258d3be0b8e0ef1a489f9cfebb3792d1006eb90",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relu Backward and Sigmoid Backward\n",
    "def relu_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "\n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "a4868b36-7c59-430d-8b4a-cf3e715e4308",
    "_uuid": "529ba6df7a42c738a50062895d3953dcc548129f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear_forward\n",
    "def linear_forward(A, W, b):\n",
    "\n",
    "    Z = np.dot(W,A)+b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "f68b45dd-e5c5-4569-8dfa-473f16c438ba",
    "_uuid": "8d264fb8742c9a33bec1ea7ae2a1987ad732a04b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#linear_activation_forward\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "f0cf4a00-9d62-47cc-a710-16a08589e6ae",
    "_uuid": "e64dafab0c6590b199581ea85be58e1235d63073",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L layers forward propagation \n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A, cache = linear_activation_forward(A,parameters[\"W\" + str(l)],parameters[\"b\" + str(l)],activation=\"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    AL, cache = linear_activation_forward(A,parameters[\"W\" + str(L)],parameters[\"b\" + str(L)],activation=\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "            \n",
    "    return AL, caches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "f796b01b-fc9f-408e-83b5-3b9e1eb3ad6e",
    "_uuid": "0e31c95d67b718f598e8a8c4cba33d39d29525ce",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Cost function\n",
    "\n",
    "def cost_function(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    cost = (-1/m)*np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n",
    "\n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "86f2fc73-9b34-4fea-8ab0-e9c4663b440b",
    "_uuid": "d36af3b0a6b72e6e4e9d16c0c228f0a2756087f7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear_backward \n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "c64d9920-ba8b-41b2-b764-350d7e586dda",
    "_uuid": "57a3263d4067e7d598237fe8541000f3d88f5b47",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear_activation_backward\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "b04c2e47-7bf3-4632-892b-bea71f52cb61",
    "_uuid": "f6d61873e37096255a890173385d74198b440caa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# backward propagation\n",
    "\n",
    "def backward_propagation(AL, Y, caches):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL,current_cache,activation=\"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 2)], caches\". Outputs: \"grads[\"dA\" + str(l + 1)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l+2)],current_cache,activation=\"relu\")\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "b8cd85d0-ccdd-4932-b804-ba0ea910353b",
    "_uuid": "5e36ba81e7066c63d63d98b75a79454d031d797d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update parameters \n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    for l in range(1,L+1):\n",
    "        parameters[\"W\"+str(l)]=parameters[\"W\" + str(l)]-learning_rate*grads[\"dW\" + str(l)]\n",
    "        parameters[\"b\"+str(l)]=parameters[\"b\" + str(l)]-learning_rate*grads[\"db\" + str(l)]\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "78646745-cd78-404f-940a-93e65f5a40c6",
    "_uuid": "3a728b579a2f41abe935e1509c87a4485ffc691a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting the size of the network \n",
    "layer_dims = [30,20,10,5,1] #5 Layer model with 3 hidden layers \n",
    "\n",
    "# Deep Learning network to classify frauds and normal\n",
    "layer_dims = [30,20,10,5,1] #5 Layer model with 3 hidden layers \n",
    "\n",
    "# Deep Learning network to classify frauds and normal\n",
    "def nn_model(X,Y,layer_dims,learning_rate=.0065, num_iterations=2500,print_cost=False):\n",
    "    costs = []\n",
    "    \n",
    "    #initialize parameters \n",
    "    parameters = intialize_parameters(layer_dims)\n",
    "    # for loop for iterations/epoch \n",
    "    for i in range(0,num_iterations):\n",
    "        #forward_propagation\n",
    "        AL, caches = forward_propagation(X, parameters)\n",
    "        \n",
    "        #compute cost\n",
    "        cost = cost_function(AL, Y)\n",
    "        \n",
    "        #backward_propagation \n",
    "        grads = backward_propagation(AL, Y, caches)\n",
    "        \n",
    "        #update parameters\n",
    "        parameters = update_parameters(parameters,grads,learning_rate)\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "e5481a56-818c-4dff-985b-b47346a357d7",
    "_uuid": "875f6e678115d3764beda535725cbc12593303ec",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 267718)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_set.shape\n",
    "Y_train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "be051add-e65c-43d4-a4a1-c03c6ca49ae1",
    "_uuid": "b2a5307516588e68850fe42fa8c61d305234bef5",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.555187\n",
      "Cost after iteration 200: 0.454774\n",
      "Cost after iteration 300: 0.380509\n",
      "Cost after iteration 400: 0.324462\n",
      "Cost after iteration 500: 0.281266\n",
      "Cost after iteration 600: 0.247295\n",
      "Cost after iteration 700: 0.220081\n",
      "Cost after iteration 800: 0.197911\n",
      "Cost after iteration 900: 0.179580\n",
      "Cost after iteration 1000: 0.164220\n",
      "Cost after iteration 1100: 0.151197\n",
      "Cost after iteration 1200: 0.140038\n",
      "Cost after iteration 1300: 0.130386\n",
      "Cost after iteration 1400: 0.121967\n",
      "Cost after iteration 1500: 0.114568\n",
      "Cost after iteration 1600: 0.108019\n",
      "Cost after iteration 1700: 0.102188\n",
      "Cost after iteration 1800: 0.096966\n",
      "Cost after iteration 1900: 0.092265\n",
      "Cost after iteration 2000: 0.088014\n",
      "Cost after iteration 2100: 0.084152\n",
      "Cost after iteration 2200: 0.080630\n",
      "Cost after iteration 2300: 0.077406\n",
      "Cost after iteration 2400: 0.074445\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICIirRQKIiLS6v8HkC3EDCvA6/0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe6b48fb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# running a model \n",
    "parameters = nn_model(X_train_set,Y_train_set,layer_dims,learning_rate=.0065,num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "51cbf8b6-a5c6-4f76-897e-1918aefabffd",
    "_uuid": "5923f247c5f338cc478f6574b343dd6e8a7451fb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict Function\n",
    "def predict(X, y, parameters):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = forward_propagation(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "fb1de1e7-e8b5-42ed-b613-0fdf4a559da9",
    "_uuid": "9599ce43b5383c122e724b7105da3464d86306bf",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9982593624634881\n"
     ]
    }
   ],
   "source": [
    "pred_train = predict(X_train_set, Y_train_set, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "1d3acfe7-ad22-4b7e-b3ea-d566be0c1b0e",
    "_uuid": "4acda72d56a5ca5f316ce8dab92c07250ca8f616",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9985955056179777\n"
     ]
    }
   ],
   "source": [
    "pred_test = predict(X_test_flatten, Y_test_flatten, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "51ee2145-21a6-4bda-8303-21db817cf1e2",
    "_uuid": "aa4c215d302f7d4f50f62ec432e08640d8c086d3",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99836161497952\n"
     ]
    }
   ],
   "source": [
    "pred_dev = predict(X_dev_flatten, Y_dev_flatten, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
